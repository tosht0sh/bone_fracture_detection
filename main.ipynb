{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86f50501",
   "metadata": {},
   "source": [
    "# Human Bone Fracture Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02252925",
   "metadata": {},
   "source": [
    "We will detect the type of bone breaks in this project. The plans we will follow is\n",
    "- ~Make a python virtual environment~\n",
    "- ~Clean and prepare Data~\n",
    "- [TODO]Create transfer learning model\n",
    "- Train and get a decent accuracy using just modifications to head\n",
    "- Unfreezing and running the model\n",
    "- Test set accuracy and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff6473fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (2.3.4)\n",
      "Requirement already satisfied: pandas in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (from pandas) (2.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Requirement already satisfied: torch in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (2.9.0+cpu)\n",
      "Requirement already satisfied: torchvision in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (0.24.0+cpu)\n",
      "Requirement already satisfied: filelock in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (from torch) (70.2.0)\n",
      "Requirement already satisfied: numpy in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (from torchvision) (2.3.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: matplotlib in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (from matplotlib) (2.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: timm in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (1.0.20)\n",
      "Requirement already satisfied: torch in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (from timm) (2.9.0+cpu)\n",
      "Requirement already satisfied: torchvision in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (from timm) (0.24.0+cpu)\n",
      "Requirement already satisfied: pyyaml in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (from timm) (6.0.3)\n",
      "Requirement already satisfied: huggingface_hub in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (from timm) (0.35.3)\n",
      "Requirement already satisfied: safetensors in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (from timm) (0.6.2)\n",
      "Requirement already satisfied: filelock in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (from huggingface_hub->timm) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (from huggingface_hub->timm) (2025.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (from huggingface_hub->timm) (25.0)\n",
      "Requirement already satisfied: requests in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (from huggingface_hub->timm) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (from huggingface_hub->timm) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (from huggingface_hub->timm) (4.15.0)\n",
      "Requirement already satisfied: colorama in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub->timm) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (from requests->huggingface_hub->timm) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (from requests->huggingface_hub->timm) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (from requests->huggingface_hub->timm) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (from requests->huggingface_hub->timm) (2025.10.5)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (from torch->timm) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (from torch->timm) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (from torch->timm) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (from torch->timm) (70.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (from sympy>=1.13.3->torch->timm) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (from jinja2->torch->timm) (2.1.5)\n",
      "Requirement already satisfied: numpy in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (from torchvision->timm) (2.3.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (from torchvision->timm) (11.3.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (from scikit-learn) (2.3.4)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\ssy340_dml\\bone_fracture_detection\\bfd\\lib\\site-packages (from scikit-learn) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu\n",
    "!pip install matplotlib\n",
    "!pip install timm\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb48478",
   "metadata": {},
   "source": [
    "### Importing dependencies and database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "defca79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\SSY340_DML\\bone_fracture_detection\\bfd\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# imorting reqd libs\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "# importing transformers and stuff for learning\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch.utils.data import WeightedRandomSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0979f70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imoprting dataset\n",
    "\n",
    "\n",
    "# Creating paths for imports\n",
    "data_path = Path.cwd()\n",
    "folder_path = data_path / \"bone.v1i.multiclass\"\n",
    "\n",
    "train_path = folder_path / \"train\"\n",
    "val_path = folder_path / \"valid\"\n",
    "test_path = folder_path / \"test\"\n",
    "\n",
    "train_csv_path = train_path / '_classes.csv'\n",
    "val_csv_path = val_path / '_classes.csv'\n",
    "test_csv_path = test_path / '_classes.csv'\n",
    "\n",
    "\n",
    "df_name = 'filename'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e14c2b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>Avulsion</th>\n",
       "      <th>Comminuted</th>\n",
       "      <th>Compression-Crush</th>\n",
       "      <th>Dislocation</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Greenstick</th>\n",
       "      <th>Hairline</th>\n",
       "      <th>Impacted</th>\n",
       "      <th>Intra-articular</th>\n",
       "      <th>Longitudinal</th>\n",
       "      <th>Oblique</th>\n",
       "      <th>Pathological</th>\n",
       "      <th>Spiral</th>\n",
       "      <th>fracture</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f1_2337.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f1_1893.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f1_2003.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f1_1846.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f1_0742.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      filename  Avulsion  Comminuted  Compression-Crush  Dislocation  \\\n",
       "0  f1_2337.jpg         1           0                  0            0   \n",
       "1  f1_1893.jpg         1           0                  0            0   \n",
       "2  f1_2003.jpg         0           1                  0            0   \n",
       "3  f1_1846.jpg         0           0                  0            0   \n",
       "4  f1_0742.jpg         1           0                  0            0   \n",
       "\n",
       "   Fracture  Greenstick  Hairline  Impacted  Intra-articular  Longitudinal  \\\n",
       "0         0           0         0         0                0             0   \n",
       "1         0           0         0         0                0             0   \n",
       "2         0           0         0         0                0             0   \n",
       "3         0           0         0         1                0             0   \n",
       "4         0           0         0         0                0             0   \n",
       "\n",
       "   Oblique  Pathological  Spiral  fracture  \n",
       "0        0             0       0         1  \n",
       "1        0             0       0         1  \n",
       "2        0             0       0         1  \n",
       "3        0             0       0         1  \n",
       "4        0             0       0         1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename training\n",
    "\n",
    "train_df = pd.read_csv(train_csv_path)\n",
    "# train_df.columns = train_df.columns.str.strip()\n",
    "\n",
    "# prefix = \"f1_\"\n",
    "# extension = \".jpg\"\n",
    "\n",
    "# file_list = sorted(os.listdir(train_path))\n",
    "# new_names = []\n",
    "\n",
    "# for i, old_name in enumerate(file_list, start=1):\n",
    "#     if old_name.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
    "#         new_name = f\"{prefix}{i:04d}{extension}\"\n",
    "#         old_path = os.path.join(train_path, old_name)\n",
    "#         new_path = os.path.join(train_path, new_name)\n",
    "#         os.rename(old_path, new_path)\n",
    "#         new_names.append((old_name, new_name))\n",
    "\n",
    "# rename_dict = dict(new_names)\n",
    "# train_df[df_name] = train_df[df_name].map(rename_dict).fillna(train_df[df_name])\n",
    "\n",
    "# train_df.to_csv(train_csv_path, index=False)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb513802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>Avulsion</th>\n",
       "      <th>Comminuted</th>\n",
       "      <th>Compression-Crush</th>\n",
       "      <th>Dislocation</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Greenstick</th>\n",
       "      <th>Hairline</th>\n",
       "      <th>Impacted</th>\n",
       "      <th>Intra-articular</th>\n",
       "      <th>Longitudinal</th>\n",
       "      <th>Oblique</th>\n",
       "      <th>Pathological</th>\n",
       "      <th>Spiral</th>\n",
       "      <th>fracture</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f2_0234.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f2_0073.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f2_0295.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f2_0241.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f2_0205.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      filename  Avulsion  Comminuted  Compression-Crush  Dislocation  \\\n",
       "0  f2_0234.jpg         0           0                  0            0   \n",
       "1  f2_0073.jpg         0           0                  0            0   \n",
       "2  f2_0295.jpg         0           0                  0            0   \n",
       "3  f2_0241.jpg         0           0                  0            0   \n",
       "4  f2_0205.jpg         0           0                  0            0   \n",
       "\n",
       "   Fracture  Greenstick  Hairline  Impacted  Intra-articular  Longitudinal  \\\n",
       "0         1           0         0         0                0             0   \n",
       "1         0           0         0         0                0             0   \n",
       "2         0           0         0         0                0             0   \n",
       "3         1           0         0         0                0             0   \n",
       "4         0           0         0         0                0             0   \n",
       "\n",
       "   Oblique  Pathological  Spiral  fracture  \n",
       "0        0             0       1         0  \n",
       "1        0             1       0         1  \n",
       "2        1             0       0         1  \n",
       "3        0             0       1         0  \n",
       "4        1             0       0         1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename val\n",
    "\n",
    "val_df = pd.read_csv(val_csv_path)\n",
    "# val_df.columns = val_df.columns.str.strip()\n",
    "\n",
    "# prefix = \"f2_\"\n",
    "# extension = \".jpg\"\n",
    "\n",
    "# file_list = sorted(os.listdir(val_path))\n",
    "# new_names = []\n",
    "\n",
    "# for i, old_name in enumerate(file_list, start=1):\n",
    "#     if old_name.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
    "#         new_name = f\"{prefix}{i:04d}{extension}\"\n",
    "#         old_path = os.path.join(val_path, old_name)\n",
    "#         new_path = os.path.join(val_path, new_name)\n",
    "#         os.rename(old_path, new_path)\n",
    "#         new_names.append((old_name, new_name))\n",
    "\n",
    "# rename_dict = dict(new_names)\n",
    "# val_df[df_name] = val_df[df_name].map(rename_dict).fillna(val_df[df_name])\n",
    "\n",
    "# val_df.to_csv(val_csv_path, index=False)\n",
    "\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2370c994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>Avulsion</th>\n",
       "      <th>Comminuted</th>\n",
       "      <th>Compression-Crush</th>\n",
       "      <th>Dislocation</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Greenstick</th>\n",
       "      <th>Hairline</th>\n",
       "      <th>Impacted</th>\n",
       "      <th>Intra-articular</th>\n",
       "      <th>Longitudinal</th>\n",
       "      <th>Oblique</th>\n",
       "      <th>Pathological</th>\n",
       "      <th>Spiral</th>\n",
       "      <th>fracture</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f3_0123.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f3_0122.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f3_0148.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f3_0007.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f3_0135.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      filename  Avulsion  Comminuted  Compression-Crush  Dislocation  \\\n",
       "0  f3_0123.jpg         0           0                  0            0   \n",
       "1  f3_0122.jpg         0           0                  0            0   \n",
       "2  f3_0148.jpg         0           0                  0            0   \n",
       "3  f3_0007.jpg         0           0                  0            0   \n",
       "4  f3_0135.jpg         0           0                  0            0   \n",
       "\n",
       "   Fracture  Greenstick  Hairline  Impacted  Intra-articular  Longitudinal  \\\n",
       "0         0           0         0         0                1             0   \n",
       "1         0           0         0         0                1             0   \n",
       "2         0           0         0         0                0             1   \n",
       "3         0           0         0         0                0             0   \n",
       "4         0           0         0         0                1             0   \n",
       "\n",
       "   Oblique  Pathological  Spiral  fracture  \n",
       "0        0             0       0         1  \n",
       "1        0             0       0         1  \n",
       "2        0             0       0         1  \n",
       "3        1             0       0         1  \n",
       "4        0             0       0         1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename test\n",
    "\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "# test_df.columns = test_df.columns.str.strip()\n",
    "\n",
    "# prefix = \"f3_\"\n",
    "# extension = \".jpg\"\n",
    "\n",
    "# file_list = sorted(os.listdir(test_path))\n",
    "# new_names = []\n",
    "\n",
    "# for i, old_name in enumerate(file_list, start=1):\n",
    "#     if old_name.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
    "#         new_name = f\"{prefix}{i:04d}{extension}\"\n",
    "#         old_path = os.path.join(test_path, old_name)\n",
    "#         new_path = os.path.join(test_path, new_name)\n",
    "#         os.rename(old_path, new_path)\n",
    "#         new_names.append((old_name, new_name))\n",
    "\n",
    "# rename_dict = dict(new_names)\n",
    "# test_df[df_name] = test_df[df_name].map(rename_dict).fillna(test_df[df_name])\n",
    "\n",
    "# test_df.to_csv(test_csv_path, index=False)\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be3198f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>Avulsion</th>\n",
       "      <th>Comminuted</th>\n",
       "      <th>Compression-Crush</th>\n",
       "      <th>Dislocation</th>\n",
       "      <th>Greenstick</th>\n",
       "      <th>Hairline</th>\n",
       "      <th>Impacted</th>\n",
       "      <th>Intra-articular</th>\n",
       "      <th>Longitudinal</th>\n",
       "      <th>Oblique</th>\n",
       "      <th>Pathological</th>\n",
       "      <th>Spiral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f1_2337.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f1_1893.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f1_2003.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f1_1846.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f1_0742.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      filename  Avulsion  Comminuted  Compression-Crush  Dislocation  \\\n",
       "0  f1_2337.jpg         1           0                  0            0   \n",
       "1  f1_1893.jpg         1           0                  0            0   \n",
       "2  f1_2003.jpg         0           1                  0            0   \n",
       "3  f1_1846.jpg         0           0                  0            0   \n",
       "4  f1_0742.jpg         1           0                  0            0   \n",
       "\n",
       "   Greenstick  Hairline  Impacted  Intra-articular  Longitudinal  Oblique  \\\n",
       "0           0         0         0                0             0        0   \n",
       "1           0         0         0                0             0        0   \n",
       "2           0         0         0                0             0        0   \n",
       "3           0         0         1                0             0        0   \n",
       "4           0         0         0                0             0        0   \n",
       "\n",
       "   Pathological  Spiral  \n",
       "0             0       0  \n",
       "1             0       0  \n",
       "2             0       0  \n",
       "3             0       0  \n",
       "4             0       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_path = folder_path / 'all'\n",
    "# os.makedirs(combined_path, exist_ok=True)\n",
    "\n",
    "# # copy into one folder\n",
    "# for file_name in os.listdir(test_path):\n",
    "#     if file_name.lower().endswith(('.jpg', '.png', '.bmp')):\n",
    "#         src_path = os.path.join(test_path, file_name)\n",
    "#         print\n",
    "#         dst_path = os.path.join(combined_path, file_name)\n",
    "#         try:\n",
    "#             shutil.copy2(src_path, dst_path)  # copy2 preserves metadata\n",
    "#             # count += 1\n",
    "#         except Exception as e:\n",
    "#             print(f\"Could not copy {file_name}: {e}\")\n",
    "\n",
    "\n",
    "# combine all datasets into one\n",
    "# combined_df = pd.concat([train_df, val_df, test_df])\n",
    "# combined_df = combined_df.drop(columns=['Fracture', 'fracture'])\n",
    "\n",
    "combined_csv_path = combined_path / '_classes.csv'\n",
    "\n",
    "# combined_df.to_csv(combined_csv_path, index=False)\n",
    "\n",
    "combined_df = pd.read_csv(combined_csv_path)\n",
    "\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5db56072",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_columns = [col for col in combined_df.columns if col != 'filename']\n",
    "\n",
    "combined_df['class'] = combined_df[class_columns].idxmax(axis=1)\n",
    "\n",
    "# print(combined_df['class'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea6d3a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "Comminuted           64\n",
      "Dislocation          47\n",
      "Compression-Crush    44\n",
      "Avulsion             41\n",
      "Greenstick           39\n",
      "Hairline             39\n",
      "Impacted             33\n",
      "Spiral               14\n",
      "Intra-articular      14\n",
      "Pathological         12\n",
      "Oblique               9\n",
      "Longitudinal          9\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# train_ratio, val_ratio, test_ratio = 0.9, 0.05, 0.05\n",
    "\n",
    "# train_df, temp_df = train_test_split(\n",
    "#     combined_df,\n",
    "#     test_size=(1 - train_ratio),\n",
    "#     stratify=combined_df['class'],\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "# val_df, test_df = train_test_split(\n",
    "#     temp_df,\n",
    "#     test_size=(test_ratio / (test_ratio + val_ratio)),\n",
    "#     stratify=temp_df['class'],\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "# print(\"Train class distribution:\")\n",
    "# print(train_df['class'].value_counts())\n",
    "\n",
    "# # print(\"\\nVal class distribution:\")\n",
    "# # print(val_df['class'].value_counts())\n",
    "\n",
    "# # print(\"\\nTest class distribution:\")\n",
    "# # print(test_df['class'].value_counts())\n",
    "\n",
    "train_df, temp_df = train_test_split(\n",
    "    combined_df, test_size=0.20, stratify=combined_df['class'], random_state=42\n",
    ")\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df, test_size=0.50, stratify=temp_df['class'], random_state=42\n",
    ")\n",
    "\n",
    "# print(train_df['class'].value_counts())\n",
    "# print(val_df['class'].value_counts())\n",
    "print(test_df['class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "64552d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch images shape: torch.Size([32, 3, 224, 224])\n",
      "Batch labels: tensor([ 1,  2,  0,  2,  1,  4,  3, 10,  1,  2,  1,  8,  1,  1,  6,  1,  8,  5,\n",
      "        10,  5,  6,  1,  6,  4,  3,  1,  0,  5,  4,  2,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "# ---- Modified Dataset Class ----\n",
    "class BoneDataset(Dataset):\n",
    "    def __init__(self, df, folder_path, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame containing 'filename' and 'class' columns.\n",
    "            folder_path (str or Path): Path to image directory.\n",
    "            transform (torchvision.transforms): Transformations to apply.\n",
    "        \"\"\"\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.folder_path = Path(folder_path)\n",
    "        self.transform = transform\n",
    "\n",
    "        # Get class mappings (string → int)\n",
    "        self.classes = sorted(self.df['class'].unique())\n",
    "        self.class_to_idx = {c: i for i, c in enumerate(self.classes)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = self.folder_path / row['filename']\n",
    "\n",
    "        # Load image\n",
    "        image = Image.open(img_path).convert(\"L\")\n",
    "\n",
    "        # Convert class name → integer label\n",
    "        # label = self.class_to_idx[row['class']]\n",
    "        # label = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        # label = self.df.iloc[idx, 1]      # class label\n",
    "        label_name = self.df.iloc[idx]['class']\n",
    "        label_idx = self.class_to_idx[label_name]\n",
    "        label = torch.tensor(label_idx, dtype=torch.long)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n",
    "# ---- Define Transforms ----\n",
    "transform = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.Grayscale(num_output_channels=3),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.5], std=[0.5]),\n",
    "])\n",
    "\n",
    "# ---- Datasets ----\n",
    "train_dataset = BoneDataset(train_df, folder_path=combined_path, transform=transform)\n",
    "valid_dataset = BoneDataset(val_df, folder_path=combined_path, transform=transform)\n",
    "test_dataset  = BoneDataset(test_df, folder_path=combined_path, transform=transform)\n",
    "\n",
    "\n",
    "# ---- Dataloaders ----\n",
    "batch_size = 32\n",
    "loader_train = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "loader_valid = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "loader_test  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# ---- Sanity check ----\n",
    "for images, labels in loader_valid:\n",
    "    print(f\"Batch images shape: {images.shape}\")\n",
    "    print(f\"Batch labels: {labels}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdd1667",
   "metadata": {},
   "source": [
    "We can use ViT, DeiT, Swin Transformer, or MedViT\n",
    "\n",
    "MedViT seems relevant but will not be easy to fine tune, and \n",
    "\n",
    "AI says we should use DeIT as it is easy to fine tune and will work well with our dataset\n",
    "\n",
    "ViT would also be valid, but it is more generic\n",
    "\n",
    "Swin would be a good idea as well but we think we follow AI and start with DeIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "88d43b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_to_label(z):\n",
    "    c = torch.argmax(z, dim=1)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "51af5398",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model, optimizer, loss_fn, train_loader, val_loader, num_epochs, print_every):\n",
    "    print(\"Starting training\")\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    train_losses, train_accs, val_losses, val_accs = [], [], [], []\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        \n",
    "        # if epoch == 4:\n",
    "        #     print(\"Unfreezing last 4 DeiT blocks for fine-tuning...\")\n",
    "        #     for name, param in model.base.blocks[-4:].named_parameters():\n",
    "        #         param.requires_grad = True\n",
    "        #     for name, param in model.base.norm.named_parameters():\n",
    "        #         param.requires_grad = True\n",
    "        #     optimizer = optim.AdamW(\n",
    "        #         filter(lambda p: p.requires_grad, model.parameters()),\n",
    "        #         lr=1e-5,\n",
    "        #         weight_decay=0.05\n",
    "        #     )\n",
    "\n",
    "        model, train_loss, train_acc = train_epoch(\n",
    "            model, optimizer, loss_fn, train_loader, val_loader, device, print_every\n",
    "        )\n",
    "        val_loss, val_acc = validate(model, loss_fn, val_loader, device)\n",
    "        print(\n",
    "            f\"Epoch {epoch}/{num_epochs}: \"\n",
    "            f\"Train loss: {sum(train_loss)/len(train_loss):.3f}, \"\n",
    "            f\"Train acc.: {sum(train_acc)/len(train_acc):.3f}, \"\n",
    "            f\"Val. loss: {val_loss:.3f}, \"\n",
    "            f\"Val. acc.: {val_acc:.3f}\"\n",
    "        )\n",
    "        train_losses.extend(train_loss)\n",
    "        train_accs.extend(train_acc)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accs.append(val_acc)\n",
    "    return model, train_losses, train_accs, val_losses, val_accs\n",
    "\n",
    "\n",
    "def train_epoch(model, optimizer, loss_fn, train_loader, val_loader, device, print_every):\n",
    "    # Train:\n",
    "    model.train()\n",
    "    train_loss_batches, train_acc_batches = [], []\n",
    "    num_batches = len(train_loader)\n",
    "    for batch_index, (x, y) in enumerate(train_loader, 1):\n",
    "        inputs, labels = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        z = model.forward(inputs)\n",
    "        # print(\"Outputs:\", z.shape)\n",
    "        # print(\"Targets:\", labels.shape)\n",
    "        labels.long()\n",
    "        loss = loss_fn(z, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss_batches.append(loss.item())\n",
    "\n",
    "        hard_preds = output_to_label(z)\n",
    "        acc_batch_avg = (hard_preds == labels).float().mean().item()\n",
    "        train_acc_batches.append(acc_batch_avg)\n",
    "\n",
    "        # If you want to print your progress more often than every epoch you can\n",
    "        # set `print_every` to the number of batches you want between every status update.\n",
    "        # Note that the print out will trigger a full validation on the full val. set => slows down training\n",
    "        if print_every is not None and batch_index % print_every == 0:\n",
    "            val_loss, val_acc = validate(model, loss_fn, val_loader, device)\n",
    "            model.train()\n",
    "            print(\n",
    "                f\"\\tBatch {batch_index}/{num_batches}: \"\n",
    "                f\"\\tTrain loss: {sum(train_loss_batches[-print_every:])/print_every:.3f}, \"\n",
    "                f\"\\tTrain acc.: {sum(train_acc_batches[-print_every:])/print_every:.3f}, \"\n",
    "                f\"\\tVal. loss: {val_loss:.3f}, \"\n",
    "                f\"\\tVal. acc.: {val_acc:.3f}\"\n",
    "            )\n",
    "\n",
    "    return model, train_loss_batches, train_acc_batches\n",
    "\n",
    "\n",
    "def validate(model, loss_fn, val_loader, device):\n",
    "    val_loss_cum = 0\n",
    "    val_acc_cum = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_index, (x, y) in enumerate(val_loader, 1):\n",
    "            inputs, labels = x.to(device), y.to(device)\n",
    "            z = model.forward(inputs)\n",
    "\n",
    "            labels.long()\n",
    "            batch_loss = loss_fn(z, labels)\n",
    "            val_loss_cum += batch_loss.item()\n",
    "            hard_preds = output_to_label(z)\n",
    "            acc_batch_avg = (hard_preds == labels).float().mean().item()\n",
    "            val_acc_cum += acc_batch_avg\n",
    "    return val_loss_cum / len(val_loader), val_acc_cum / len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "56da7f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "c:\\SSY340_DML\\bone_fracture_detection\\bfd\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\toshi\\.cache\\huggingface\\hub\\models--timm--deit_small_patch16_224.fb_in1k. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "# loading DeIT from timm\n",
    "num_classes = 12\n",
    "# base_model = timm.create_model(\n",
    "#     'swin_tiny_patch4_window7_224',\n",
    "#     pretrained=True,\n",
    "#     num_classes=num_classes,   # <— forces classification head\n",
    "#     global_pool='avg'          # <— ensures 7×7 gets averaged\n",
    "# )\n",
    "\n",
    "# # base_model.head\n",
    "\n",
    "# in_features = base_model.head.in_features\n",
    "# base_model.head = nn.Linear(in_features, num_classes)\n",
    "\n",
    "# x = torch.randn(32, 3, 224, 224)\n",
    "# out = base_model(x)\n",
    "# print(out.shape)\n",
    "\n",
    "base_model = timm.create_model('deit_small_patch16_224', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "eccb2c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freezing layers\n",
    "\n",
    "for param in base_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "73b3063a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating base model and head model\n",
    "\n",
    "base_model.head = nn.Identity() \n",
    "\n",
    "class HeadModel(nn.Module):\n",
    "    def __init__(self, in_features, num_classes):\n",
    "        super(HeadModel, self).__init__()\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(in_features, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.head(x)\n",
    "    \n",
    "head_model = HeadModel(in_features=384, num_classes=12)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "ad4b53e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FullModel(\n",
      "  (base): VisionTransformer(\n",
      "    (patch_embed): PatchEmbed(\n",
      "      (proj): Conv2d(3, 384, kernel_size=(16, 16), stride=(16, 16))\n",
      "      (norm): Identity()\n",
      "    )\n",
      "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "    (patch_drop): Identity()\n",
      "    (norm_pre): Identity()\n",
      "    (blocks): Sequential(\n",
      "      (0): Block(\n",
      "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): Identity()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): Identity()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (1): Block(\n",
      "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): Identity()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): Identity()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (2): Block(\n",
      "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): Identity()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): Identity()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (3): Block(\n",
      "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): Identity()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): Identity()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (4): Block(\n",
      "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): Identity()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): Identity()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (5): Block(\n",
      "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): Identity()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): Identity()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (6): Block(\n",
      "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): Identity()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): Identity()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (7): Block(\n",
      "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): Identity()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): Identity()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (8): Block(\n",
      "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): Identity()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): Identity()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (9): Block(\n",
      "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): Identity()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): Identity()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (10): Block(\n",
      "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): Identity()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): Identity()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (11): Block(\n",
      "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): Identity()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): Identity()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "    (fc_norm): Identity()\n",
      "    (head_drop): Dropout(p=0.0, inplace=False)\n",
      "    (head): Identity()\n",
      "  )\n",
      "  (head): HeadModel(\n",
      "    (head): Sequential(\n",
      "      (0): Linear(in_features=384, out_features=512, bias=True)\n",
      "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Dropout(p=0.3, inplace=False)\n",
      "      (4): Linear(in_features=512, out_features=12, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# creating full model\n",
    "\n",
    "class FullModel(nn.Module):\n",
    "    def __init__(self, base_model, head_model):\n",
    "        super(FullModel, self).__init__()\n",
    "        self.base = base_model\n",
    "        self.head = head_model\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base(x)\n",
    "        # print(x.shape)\n",
    "        x = self.head(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "# base_model.head = head_model\n",
    "\n",
    "model = FullModel(base_model, head_model)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "4a3a2761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing classwise loss weights\n",
    "class_counts = train_df['class'].value_counts().sort_index()\n",
    "total = sum(class_counts)\n",
    "class_weights = [total / c for c in class_counts]  # inverse frequency\n",
    "# class_weights = 1.0 / torch.tensor(class_counts.values, dtype=torch.float)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "\n",
    "loss = nn.CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "7d691494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "Epoch 1/15: Train loss: 2.515, Train acc.: 0.119, Val. loss: 2.385, Val. acc.: 0.214\n",
      "Epoch 2/15: Train loss: 2.270, Train acc.: 0.247, Val. loss: 2.245, Val. acc.: 0.304\n",
      "Epoch 3/15: Train loss: 2.130, Train acc.: 0.320, Val. loss: 2.145, Val. acc.: 0.339\n",
      "Epoch 4/15: Train loss: 2.024, Train acc.: 0.359, Val. loss: 2.078, Val. acc.: 0.378\n",
      "Epoch 5/15: Train loss: 1.916, Train acc.: 0.404, Val. loss: 2.017, Val. acc.: 0.385\n",
      "Epoch 6/15: Train loss: 1.845, Train acc.: 0.411, Val. loss: 1.976, Val. acc.: 0.413\n",
      "Epoch 7/15: Train loss: 1.781, Train acc.: 0.434, Val. loss: 1.933, Val. acc.: 0.419\n",
      "Epoch 8/15: Train loss: 1.724, Train acc.: 0.465, Val. loss: 1.894, Val. acc.: 0.434\n",
      "Epoch 9/15: Train loss: 1.663, Train acc.: 0.472, Val. loss: 1.875, Val. acc.: 0.440\n",
      "Epoch 10/15: Train loss: 1.611, Train acc.: 0.495, Val. loss: 1.848, Val. acc.: 0.447\n",
      "Epoch 11/15: Train loss: 1.576, Train acc.: 0.514, Val. loss: 1.837, Val. acc.: 0.442\n",
      "Epoch 12/15: Train loss: 1.528, Train acc.: 0.533, Val. loss: 1.803, Val. acc.: 0.455\n",
      "Epoch 13/15: Train loss: 1.477, Train acc.: 0.549, Val. loss: 1.786, Val. acc.: 0.455\n",
      "Epoch 14/15: Train loss: 1.442, Train acc.: 0.555, Val. loss: 1.763, Val. acc.: 0.465\n",
      "Epoch 15/15: Train loss: 1.399, Train acc.: 0.574, Val. loss: 1.748, Val. acc.: 0.481\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "\n",
    "# loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-5,weight_decay=0.05)\n",
    "num_epochs = 15\n",
    "print_every = None\n",
    "\n",
    "model, train_losses, train_accs, val_losses, val_accs = training_loop(model, optimizer, loss, loader_train, loader_valid, num_epochs, print_every)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669ced52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting results\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bfd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
