{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f72e3db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\SSY340_DML\\bone_fracture_detection\\bfd\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/pkdarabi/bone-break-classification-image-dataset?dataset_version_number=4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28.4M/28.4M [00:02<00:00, 12.2MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\toshi\\.cache\\kagglehub\\datasets\\pkdarabi\\bone-break-classification-image-dataset\\versions\\4\n"
     ]
    }
   ],
   "source": [
    "# import ds from kaggle\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"pkdarabi/bone-break-classification-image-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9d403bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import random_split, DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74fecb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(os.listdir(path))\n",
    "\n",
    "local_folder = \"./dataset2\"\n",
    "\n",
    "# os.mkdir(local_folder)\n",
    "\n",
    "# shutil.copytree(path, local_folder, dirs_exist_ok=True)\n",
    "\n",
    "# rename folder name\n",
    "old_name =  './dataset2/fractures/Bone Break CLassification'\n",
    "new_name = './dataset2/fractures2'\n",
    "\n",
    "# os.rename(old_name, new_name)\n",
    "\n",
    "folder_name = \"./dataset2/fractures2\"\n",
    "train_target = \"./dataset2/train\"\n",
    "test_target = \"./dataset2/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1692e0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go through each class\n",
    "for class_name in os.listdir(folder_name):\n",
    "    class_path = os.path.join(folder_name, class_name)\n",
    "    if not os.path.isdir(class_path):\n",
    "        continue\n",
    "\n",
    "    # Define source train/test subfolders\n",
    "    src_train = os.path.join(class_path, \"Train\")\n",
    "    src_test = os.path.join(class_path, \"Test\")\n",
    "\n",
    "    # Define target train/test class folders\n",
    "    tgt_train_class = os.path.join(train_target, class_name)\n",
    "    tgt_test_class = os.path.join(test_target, class_name)\n",
    "    os.makedirs(tgt_train_class, exist_ok=True)\n",
    "    os.makedirs(tgt_test_class, exist_ok=True)\n",
    "\n",
    "    # Copy training images\n",
    "    if os.path.exists(src_train):\n",
    "        for file in os.listdir(src_train):\n",
    "            src_file = os.path.join(src_train, file)\n",
    "            dst_file = os.path.join(tgt_train_class, file)\n",
    "            if os.path.isfile(src_file):\n",
    "                shutil.copy(src_file, dst_file)\n",
    "\n",
    "    # Copy testing images\n",
    "    if os.path.exists(src_test):\n",
    "        for file in os.listdir(src_test):\n",
    "            src_file = os.path.join(src_test, file)\n",
    "            dst_file = os.path.join(tgt_test_class, file)\n",
    "            if os.path.isfile(src_file):\n",
    "                shutil.copy(src_file, dst_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e68f1c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms for DeiT (224x224 input size)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Set paths\n",
    "train_dir = r\"C:\\SSY340_DML\\bone_fracture_detection\\dataset2\\train\"\n",
    "test_dir = r\"C:\\SSY340_DML\\bone_fracture_detection\\dataset2\\test\"\n",
    "\n",
    "\n",
    "class FractureDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.class_to_idx = {}\n",
    "\n",
    "        # Assign numeric labels to each folder\n",
    "        for idx, class_name in enumerate(sorted(os.listdir(root_dir))):\n",
    "            class_path = os.path.join(root_dir, class_name)\n",
    "            if os.path.isdir(class_path):\n",
    "                self.class_to_idx[class_name] = idx\n",
    "                for img_file in os.listdir(class_path):\n",
    "                    if img_file.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
    "                        self.image_paths.append(os.path.join(class_path, img_file))\n",
    "                        self.labels.append(idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Create data loaders\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "train_dataset = FractureDataset(train_dir, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "test_dataset = FractureDataset(test_dir, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6e83ef5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize 6 random images from train_data\n",
    "total_size = 989\n",
    "train_size = int(0.8 * total_size)  \n",
    "val_size = total_size - train_size  \n",
    "\n",
    "train_subset, val_subset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_subset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2649eab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_to_label(z):\n",
    "    c = torch.argmax(z, dim=1)\n",
    "    return c\n",
    "\n",
    "def training_loop(model, optimizer, loss_fn, train_loader, val_loader, num_epochs, print_every):\n",
    "    print(\"Starting training\")\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    train_losses, train_accs, val_losses, val_accs = [], [], [], []\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        \n",
    "        # optimizer = optim.AdamW(\n",
    "        #         filter(lambda p: p.requires_grad, model.parameters()),\n",
    "        #         lr=lr,\n",
    "        #         weight_decay=0.05\n",
    "        #     )\n",
    "        \n",
    "        if epoch == 15:\n",
    "            print(\"Unfreezing last 2 DeiT blocks for fine-tuning...\")\n",
    "            for name, param in model.base.blocks[-3:].named_parameters():\n",
    "                param.requires_grad = True\n",
    "            for name, param in model.base.norm.named_parameters():\n",
    "                param.requires_grad = True\n",
    "            optimizer = optim.AdamW(\n",
    "                filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                lr=7e-6,\n",
    "                weight_decay=0.05\n",
    "            )\n",
    "\n",
    "\n",
    "        if epoch == 30:\n",
    "            print(\"Unfreezing last 6 DeiT blocks for fine-tuning...\")\n",
    "            for name, param in model.base.blocks[-7:].named_parameters():\n",
    "                param.requires_grad = True\n",
    "            for name, param in model.base.norm.named_parameters():\n",
    "                param.requires_grad = True\n",
    "            optimizer = optim.AdamW(\n",
    "                filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                lr=5e-6,\n",
    "                weight_decay=0.05\n",
    "            )\n",
    "\n",
    "        # if epoch == 35:\n",
    "        #     print(\"Unfreezing all DeiT blocks for fine-tuning...\")\n",
    "        #     for name, param in model.base.blocks.named_parameters():\n",
    "        #         param.requires_grad = True\n",
    "        #     for name, param in model.base.norm.named_parameters():\n",
    "        #         param.requires_grad = True\n",
    "        #     optimizer = optim.AdamW(\n",
    "        #         filter(lambda p: p.requires_grad, model.parameters()),\n",
    "        #         lr=7e-7,\n",
    "        #         weight_decay=0.05\n",
    "        #     )\n",
    "\n",
    "        model, train_loss, train_acc = train_epoch(\n",
    "            model, optimizer, loss_fn, train_loader, val_loader, device, print_every\n",
    "        )\n",
    "        val_loss, val_acc = validate(model, loss_fn, val_loader, device)\n",
    "        print(\n",
    "            f\"Epoch {epoch}/{num_epochs}: \"\n",
    "            f\"Train loss: {sum(train_loss)/len(train_loss):.3f}, \"\n",
    "            f\"Train acc.: {sum(train_acc)/len(train_acc):.3f}, \"\n",
    "            f\"Val. loss: {val_loss:.3f}, \"\n",
    "            f\"Val. acc.: {val_acc:.3f}, \"\n",
    "            # f\"LR: {lr:.3f}, \"\n",
    "        )\n",
    "        train_losses.extend(train_loss)\n",
    "        train_accs.extend(train_acc)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accs.append(val_acc)\n",
    "    return model, train_losses, train_accs, val_losses, val_accs\n",
    "\n",
    "\n",
    "def train_epoch(model, optimizer, loss_fn, train_loader, val_loader, device, print_every):\n",
    "    # Train:\n",
    "    model.train()\n",
    "    train_loss_batches, train_acc_batches = [], []\n",
    "    num_batches = len(train_loader)\n",
    "    for batch_index, (x, y) in enumerate(train_loader, 1):\n",
    "        inputs, labels = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # with torch.no_grad():\n",
    "        #     x = model.blocks[:-1](inputs)\n",
    "\n",
    "        # x = model.blocks[-1:](x)\n",
    "        # outputs = model.forward(inputs)\n",
    "        z = model.forward(inputs)\n",
    "        # print(\"Outputs:\", z.shape)\n",
    "        # print(\"Targets:\", labels.shape)\n",
    "        labels.long()\n",
    "        loss = loss_fn(z, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss_batches.append(loss.item())\n",
    "\n",
    "        hard_preds = output_to_label(z)\n",
    "        acc_batch_avg = (hard_preds == labels).float().mean().item()\n",
    "        train_acc_batches.append(acc_batch_avg)\n",
    "\n",
    "        # If you want to print your progress more often than every epoch you can\n",
    "        # set `print_every` to the number of batches you want between every status update.\n",
    "        # Note that the print out will trigger a full validation on the full val. set => slows down training\n",
    "        if print_every is not None and batch_index % print_every == 0:\n",
    "            val_loss, val_acc = validate(model, loss_fn, val_loader, device)\n",
    "            model.train()\n",
    "            print(\n",
    "                f\"\\tBatch {batch_index}/{num_batches}: \"\n",
    "                f\"\\tTrain loss: {sum(train_loss_batches[-print_every:])/print_every:.3f}, \"\n",
    "                f\"\\tTrain acc.: {sum(train_acc_batches[-print_every:])/print_every:.3f}, \"\n",
    "                f\"\\tVal. loss: {val_loss:.3f}, \"\n",
    "                f\"\\tVal. acc.: {val_acc:.3f}\"\n",
    "            )\n",
    "\n",
    "    return model, train_loss_batches, train_acc_batches\n",
    "\n",
    "\n",
    "def validate(model, loss_fn, val_loader, device):\n",
    "    val_loss_cum = 0\n",
    "    val_acc_cum = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_index, (x, y) in enumerate(val_loader, 1):\n",
    "            inputs, labels = x.to(device), y.to(device)\n",
    "            z = model.forward(inputs)\n",
    "\n",
    "            labels.long()\n",
    "            batch_loss = loss_fn(z, labels)\n",
    "            val_loss_cum += batch_loss.item()\n",
    "            hard_preds = output_to_label(z)\n",
    "            acc_batch_avg = (hard_preds == labels).float().mean().item()\n",
    "            val_acc_cum += acc_batch_avg\n",
    "    return val_loss_cum / len(val_loader), val_acc_cum / len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b56a2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "model = timm.create_model('deit_base_patch16_224', pretrained=True)\n",
    "\n",
    "model.head = nn.Linear(model.head.in_features, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daea0227",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class_counts = 10\n",
    "total = sum(class_counts)\n",
    "class_weights = [total / c for c in class_counts]  # inverse frequency\n",
    "\n",
    "loss = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "\n",
    "lr = 8e-6\n",
    "optimizer = optim.AdamW(model.parameters(), lr=8e-6,weight_decay=0.05)\n",
    "num_epochs = 40\n",
    "print_every = None\n",
    "\n",
    "model, train_losses, train_accs, val_losses, val_accs = training_loop(model, optimizer, loss, train_loader, val_loader, num_epochs, print_every)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bfd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
